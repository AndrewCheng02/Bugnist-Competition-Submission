{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2ee25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c9e09dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/andrewcheng/Documents/GitHub/Debuggers/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d9d594",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segment_mixture'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mBugNIST_metric\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegment_mixture\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtifffile\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mVolumesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VolumesDataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'segment_mixture'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import BugNIST_metric\n",
    "import segment_mixture\n",
    "import tifffile\n",
    "from VolumesDataset import VolumesDataset\n",
    "\n",
    "# CNN\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c8d9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/andrewcheng/Documents/GitHub/Debuggers/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = os.path.abspath('../') + '/'\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b063ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_train_fp = root + \"BugNIST_DATA/train/AC/bcrick_10_000.tif\"\n",
    "example_valid_fp = root + 'BugNIST_DATA/validation/mix_02_006.tif'\n",
    "example_valid_gen_fps = [root + 'temp/mix_02_006/bug_' + str(i) + '.tif' for i in range(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e358f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_custom_train_fp = root + \"BugNIST_DATA/custom_train/AC/bcrick_10_000.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c354f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import (exposure, feature, filters, io, measure,\n",
    "                      morphology, restoration, segmentation, transform,\n",
    "                      util)\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38baba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bug1 = io.imread(example_custom_train_fp)\n",
    "bug2 = io.imread(example_train_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6ea8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the bug with napari\n",
    "viewer = napari.view_image(bug1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f766635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the bug with napari\n",
    "viewer = napari.view_image(bug2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32a53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1df8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel(\n",
      "  (conv_layer1): Sequential(\n",
      "    (0): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_layer2): Sequential(\n",
      "    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=376320, out_features=64, bias=True)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (classifier): Linear(in_features=64, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the 3D CNN\n",
    "num_classes = 12\n",
    "\n",
    "# Create CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.conv_layer1 = self._conv_layer_set(3, 32)\n",
    "        self.conv_layer2 = self._conv_layer_set(32, 64)\n",
    "        self.fc1 = nn.Linear(376320, 64)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.drop=nn.Dropout(p=0.50)\n",
    "        self.classifier = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def _conv_layer_set(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(\n",
    "        nn.Conv3d(in_c, out_c, kernel_size=(3, 3, 3), padding=0),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.MaxPool3d((2, 2, 2)),\n",
    "        )\n",
    "        return conv_layer\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.drop(out)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.drop(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "#Definition of hyperparameters\n",
    "n_iters = 100\n",
    "num_epochs = 50\n",
    "\n",
    "# Create CNN\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNModel() #.to(device)\n",
    "\n",
    "#model.cuda()\n",
    "print(model)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.04\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9ad0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = root + 'Notebooks/models'\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f99f70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_bug = {0: 'ac',\n",
    " 1: 'bc',\n",
    " 2: 'bf',\n",
    " 3: 'bl',\n",
    " 4: 'bp',\n",
    " 5: 'cf',\n",
    " 6: 'gh',\n",
    " 7: 'ma',\n",
    " 8: 'ml',\n",
    " 9: 'pp',\n",
    " 10: 'sl',\n",
    " 11: 'wo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53161125",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_with_unsqueeze = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: torch.from_numpy(img)),  # Convert to PyTorch tensor\n",
    "    transforms.Lambda(lambda img: torch.unsqueeze(img, dim=0).repeat(3, 1, 1, 1)) # Add more transforms as needed\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9309fff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 92, 92)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tifffile.imread(example_valid_gen_fps[4]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1790c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make single bug prediciton\n",
    "def predict_bugs(filepaths):\n",
    " \n",
    "    # read it in\n",
    "    # cast into tensor\n",
    "    data = pd.DataFrame({'FileLoc' : filepaths, 'BugType' : ['bl'] * len(filepaths)})\n",
    "    dataset = VolumesDataset(data, transform=transform_with_unsqueeze)    \n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=1)\n",
    "    \n",
    "\n",
    "    # Predict\n",
    "    preds = []\n",
    "    \n",
    "    for img, label in data_loader:\n",
    "        with torch.no_grad():\n",
    "            out = model(img)\n",
    "            pred = torch.argmax(out)\n",
    "            preds.append(int_to_bug[int(pred)])\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63252885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bf', 'bc', 'ml', 'bc', 'bc', 'bc', 'bf', 'bc', 'bf', 'ma', 'ml', 'sl', 'wo']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_bugs(example_valid_gen_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348ef8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Validation\n",
    "def predict_validation(filepath):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    watershed_centers, segment_paths = segment_mixture.segment_bugs(filepath)\n",
    "    segment_pred = predict_bugs(segment_paths)\n",
    "    \n",
    "    # Segment\n",
    "    for watershed_center, pred in zip(watershed_centers, segment_pred):\n",
    "        x, y, z = watershed_center\n",
    "        \n",
    "        res.append(pred + ';' + str(x) + ';' + str(y) + ';' + str(z))\n",
    "    \n",
    "    return ';'.join(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6aea6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bf;61;45;47;bc;39;47;79;ml;95;38;47;bc;58;71;57;bc;51;29;22;bc;60;14;41;bf;65;19;29;bc;41;61;75;bf;58;47;76;ma;50;42;48;ml;38;63;20;sl;46;56;29;wo;58;41;29'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_validation(example_valid_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a935abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With File Paths\n",
    "bug_labels = {'AC' : 'Brown Cricket', 'BC' : 'Black Cricket', 'BF' : 'Blow fly', \n",
    "              'BL' : 'Buffalo Beetle Larva' , 'BP' : 'Blow Fly Pupa', 'CF' : 'Curly-wing Fly', 'GH' : 'Grasshopper',\n",
    "              'MA' : 'Maggot', 'ML' : 'Mealworm', 'PP' : 'Green Bottle Fly Pupa' , 'SL' : 'Soldier Fly Larva',\n",
    "              'WO' : 'Woodlice'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30faf9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/andrewcheng/Documents/GitHub/Debuggers/...</td>\n",
       "      <td>Brown Cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/andrewcheng/Documents/GitHub/Debuggers/...</td>\n",
       "      <td>Brown Cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/andrewcheng/Documents/GitHub/Debuggers/...</td>\n",
       "      <td>Brown Cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/andrewcheng/Documents/GitHub/Debuggers/...</td>\n",
       "      <td>Brown Cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/andrewcheng/Documents/GitHub/Debuggers/...</td>\n",
       "      <td>Brown Cricket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fp           type\n",
       "0  /Users/andrewcheng/Documents/GitHub/Debuggers/...  Brown Cricket\n",
       "1  /Users/andrewcheng/Documents/GitHub/Debuggers/...  Brown Cricket\n",
       "2  /Users/andrewcheng/Documents/GitHub/Debuggers/...  Brown Cricket\n",
       "3  /Users/andrewcheng/Documents/GitHub/Debuggers/...  Brown Cricket\n",
       "4  /Users/andrewcheng/Documents/GitHub/Debuggers/...  Brown Cricket"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Data\n",
    "\n",
    "train_fp = root + 'BugNIST_DATA/train/'\n",
    "\n",
    "A = []\n",
    "train_file_paths = []\n",
    "\n",
    "for i, v in bug_labels.items():\n",
    "    for fp in os.listdir(train_fp + i):\n",
    "        train_file_paths.append(train_fp + i + '/' + fp)\n",
    "        A.append({'fp' : train_fp + i + '/' + fp, 'type' : v})\n",
    "        \n",
    "train = pd.DataFrame(A)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10283827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9154, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05efacf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>centerpoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix_02_006.tif</td>\n",
       "      <td>bl;48.61;39.14;96.19;bl;77.71;53.14;57.17;pp;5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix_02_011.tif</td>\n",
       "      <td>ml;77.86;46.26;57.79;sl;41.14;61.93;32.37;sl;5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mix_03_001.tif</td>\n",
       "      <td>ml;54.20;34.58;81.43;ml;59.60;41.94;60.72;ml;4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_03_003.tif</td>\n",
       "      <td>wo;44.37;27.71;85.18;wo;30.04;28.46;58.76;wo;4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_03_004.tif</td>\n",
       "      <td>pp;74.65;44.18;52.53;pp;30.69;25.53;54.51;pp;1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                       centerpoints\n",
       "0  mix_02_006.tif  bl;48.61;39.14;96.19;bl;77.71;53.14;57.17;pp;5...\n",
       "1  mix_02_011.tif  ml;77.86;46.26;57.79;sl;41.14;61.93;32.37;sl;5...\n",
       "2  mix_03_001.tif  ml;54.20;34.58;81.43;ml;59.60;41.94;60.72;ml;4...\n",
       "3  mix_03_003.tif  wo;44.37;27.71;85.18;wo;30.04;28.46;58.76;wo;4...\n",
       "4  mix_03_004.tif  pp;74.65;44.18;52.53;pp;30.69;25.53;54.51;pp;1..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation Data\n",
    "validation = pd.read_csv(root + 'BugNIST_DATA/validation/validation.csv')\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52897bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5948c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(out_path = 'baseline.csv'):\n",
    "    \n",
    "    validation_fp = root + 'BugNIST_DATA/validation/'\n",
    "\n",
    "    validation = pd.read_csv(validation_fp + 'validation.csv')\n",
    "    validation['centerpoints'] = validation['filename'].apply(lambda x : predict_validation(validation_fp + x))\n",
    "    \n",
    "    # Save predictions to csv\n",
    "    validation.set_index('filename').to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1a69eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc4cabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = root + 'Notebooks/baseline.csv'\n",
    "target = root + 'BugNIST_DATA/validation/validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc0388cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.06521705612220399\n"
     ]
    }
   ],
   "source": [
    "BugNIST_metric.main(pred, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
